<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Red Hat advances Debezium CDC connectors for Apache Kafka support to Technical Preview</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/K4vla7dkDoQ/" /><category term="Apache Kafka" scheme="searchisko:content:tags" /><category term="debezium" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="integration" scheme="searchisko:content:tags" /><author><name>Hugo Guerrero</name></author><id>searchisko:content:id:jbossorg_blog-red_hat_advances_debezium_cdc_connectors_for_apache_kafka_support_to_technical_preview</id><updated>2019-11-22T08:05:18Z</updated><published>2019-11-22T08:05:18Z</published><content type="html">&lt;p&gt;&lt;span style="font-weight: 400;"&gt;After a couple of months in Developer Preview, the Debezium &lt;/span&gt;&lt;a href="https://www.redhat.com/en/topics/integration/what-is-apache-kafka"&gt;&lt;span style="font-weight: 400;"&gt;Apache Kafka&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; connectors for change data capture (CDC) are now available as a &lt;/span&gt;&lt;a href="https://access.redhat.com/support/offerings/techpreview"&gt;&lt;span style="font-weight: 400;"&gt;Technical Preview&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; as part of the Q4 release of &lt;/span&gt;&lt;a href="https://www.redhat.com/en/products/integration"&gt;&lt;span style="font-weight: 400;"&gt;Red Hat Integration&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;. Technology Preview features provide early access to upcoming product innovations, enabling you to test functionality and provide feedback during the development process.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Red Hat Integration provides Debezium connectors for capturing changes from the following databases:&lt;/span&gt;&lt;/p&gt; &lt;ul&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;MySQL Connector&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;PostgreSQL Connector&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;MongoDB Connector&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;SQL Server Connector&lt;/span&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Debezium connectors are based on the popular&lt;/span&gt;&lt;a href="https://kafka.apache.org/documentation.html#connect"&gt; &lt;span style="font-weight: 400;"&gt;Apache Kafka Connect API&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; and are suitable to be deployed along &lt;/span&gt;&lt;a href="https://www.redhat.com/en/resources/amq-streams-datasheet"&gt;&lt;span style="font-weight: 400;"&gt; &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Red Hat AMQ Streams&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; Kafka clusters. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;AMQ Streams is a Red Hat Integration component that provides Red Hat’s distribution of Apache Kafka and the popular &lt;/span&gt;&lt;a href="https://www.cncf.io/sandbox-projects/"&gt;&lt;span style="font-weight: 400;"&gt;CNCF sandbox&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; project &lt;/span&gt;&lt;a href="https://strimzi.io/"&gt;&lt;span style="font-weight: 400;"&gt;Strimzi&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;. AMQ Streams makes running and managing Kafka an OpenShift-native experience&lt;/span&gt;&lt;span style="font-weight: 400;"&gt; by delivering OpenShift Operators, which provide a simplified and automated way to deploy, manage, upgrade, and configure a Kafka ecosystem on OpenShift.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;With this addition, Red Hat Integration now makes available more components to connect systems along the whole enterprise ecosystem. Along with &lt;/span&gt;&lt;a href="https://developers.redhat.com/products/fuse/connectors"&gt;&lt;span style="font-weight: 400;"&gt;Apache Camel’s 200 connectors&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;, users can connect to practically everything—from legacy systems to Software-as-a-service (SaaS) applications, and application programming interfaces (APIs) to Internet of Things (IoT) devices.&lt;/span&gt;&lt;/p&gt; &lt;h3&gt;&lt;span style="font-weight: 400;"&gt;What is Change Data Capture (CDC)?&lt;/span&gt;&lt;/h3&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Change Data Capture, or CDC, is a well-established software design pattern for a system that monitors and captures the changes in data so that other software can respond to those changes. CDC captures row-level changes to database tables and passes corresponding change events to a data streaming bus. Applications can read these change event streams and access the change events in the order in which they occurred.&lt;/span&gt;&lt;/p&gt; &lt;h3&gt;&lt;span style="font-weight: 400;"&gt;What is Debezium?&lt;/span&gt;&lt;/h3&gt; &lt;p&gt;&lt;a href="https://debezium.io/"&gt;&lt;span style="font-weight: 400;"&gt;Debezium&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; is a set of distributed services that captures row-level changes in databases so that applications can see and respond to those changes. Debezium connectors record all events to a Red Hat AMQ Streams Kafka cluster, and applications consume those events through AMQ Streams.&lt;/span&gt;&lt;/p&gt; &lt;h3&gt;&lt;span style="font-weight: 400;"&gt;CDC in action with Debezium&lt;/span&gt;&lt;/h3&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;You can check Sadhana Nandakumar’s  &lt;/span&gt;&lt;a href="https://developers.redhat.com/blog/2019/09/03/cdc-pipeline-with-red-hat-amq-streams-and-red-hat-fuse/"&gt;&lt;span style="font-weight: 400;"&gt;blog post&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; in which she explains how to make use of Red Hat Integration to create a complete CDC pipeline. In the example she captures the changes as they occur using Debezium and streams them using Red Hat AMQ Streams. Then, she filters and transforms the data using Red Hat Fuse and sends it to Elasticsearch, where the data can be further analyzed or used by downstream systems.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;You can download the Red Hat Integration Debezium CDC Technical Preview connectors from the &lt;/span&gt;&lt;a href="https://developers.redhat.com/products/amq/download"&gt;&lt;span style="font-weight: 400;"&gt;Red Hat Developer site&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;. If you have requests or questions related to running the Debezium Technical Preview, please let us know by sending an email to the &lt;/span&gt;&lt;a href="mailto:debezium-cdc-preview@redhat.com"&gt;&lt;span style="font-weight: 400;"&gt;debezium-cdc-preview mailing list&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F22%2Fred-hat-advances-debezium-cdc-connectors-for-apache-kafka-support-to-technical-preview%2F&amp;#38;linkname=Red%20Hat%20advances%20Debezium%20CDC%20connectors%20for%20Apache%20Kafka%20support%20to%20Technical%20Preview" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F22%2Fred-hat-advances-debezium-cdc-connectors-for-apache-kafka-support-to-technical-preview%2F&amp;#38;linkname=Red%20Hat%20advances%20Debezium%20CDC%20connectors%20for%20Apache%20Kafka%20support%20to%20Technical%20Preview" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F22%2Fred-hat-advances-debezium-cdc-connectors-for-apache-kafka-support-to-technical-preview%2F&amp;#38;linkname=Red%20Hat%20advances%20Debezium%20CDC%20connectors%20for%20Apache%20Kafka%20support%20to%20Technical%20Preview" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F22%2Fred-hat-advances-debezium-cdc-connectors-for-apache-kafka-support-to-technical-preview%2F&amp;#38;linkname=Red%20Hat%20advances%20Debezium%20CDC%20connectors%20for%20Apache%20Kafka%20support%20to%20Technical%20Preview" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F22%2Fred-hat-advances-debezium-cdc-connectors-for-apache-kafka-support-to-technical-preview%2F&amp;#38;linkname=Red%20Hat%20advances%20Debezium%20CDC%20connectors%20for%20Apache%20Kafka%20support%20to%20Technical%20Preview" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F22%2Fred-hat-advances-debezium-cdc-connectors-for-apache-kafka-support-to-technical-preview%2F&amp;#38;linkname=Red%20Hat%20advances%20Debezium%20CDC%20connectors%20for%20Apache%20Kafka%20support%20to%20Technical%20Preview" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F22%2Fred-hat-advances-debezium-cdc-connectors-for-apache-kafka-support-to-technical-preview%2F&amp;#38;linkname=Red%20Hat%20advances%20Debezium%20CDC%20connectors%20for%20Apache%20Kafka%20support%20to%20Technical%20Preview" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F22%2Fred-hat-advances-debezium-cdc-connectors-for-apache-kafka-support-to-technical-preview%2F&amp;#038;title=Red%20Hat%20advances%20Debezium%20CDC%20connectors%20for%20Apache%20Kafka%20support%20to%20Technical%20Preview" data-a2a-url="https://developers.redhat.com/blog/2019/11/22/red-hat-advances-debezium-cdc-connectors-for-apache-kafka-support-to-technical-preview/" data-a2a-title="Red Hat advances Debezium CDC connectors for Apache Kafka support to Technical Preview"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/11/22/red-hat-advances-debezium-cdc-connectors-for-apache-kafka-support-to-technical-preview/"&gt;Red Hat advances Debezium CDC connectors for Apache Kafka support to Technical Preview&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/K4vla7dkDoQ" height="1" width="1" alt=""/&gt;</content><summary>After a couple of months in Developer Preview, the Debezium Apache Kafka connectors for change data capture (CDC) are now available as a Technical Preview as part of the Q4 release of Red Hat Integration. Technology Preview features provide early access to upcoming product innovations, enabling you to test functionality and provide feedback during the development process. Red Hat Integration provi...</summary><dc:creator>Hugo Guerrero</dc:creator><dc:date>2019-11-22T08:05:18Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/11/22/red-hat-advances-debezium-cdc-connectors-for-apache-kafka-support-to-technical-preview/</feedburner:origLink></entry><entry><title>Cloud-native integration with Kubernetes and Camel K</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/AzTPzACP1HY/" /><category term="Camel K" scheme="searchisko:content:tags" /><category term="cloud" scheme="searchisko:content:tags" /><category term="devnation" scheme="searchisko:content:tags" /><category term="events" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><author><name>Editorial Team</name></author><id>searchisko:content:id:jbossorg_blog-cloud_native_integration_with_kubernetes_and_camel_k</id><updated>2019-11-22T08:00:57Z</updated><published>2019-11-22T08:00:57Z</published><content type="html">&lt;p&gt;Our first &lt;a href="https://developers.redhat.com/devnationlive-india/"&gt;DevNation Live regional event was held in Bengaluru, India&lt;/a&gt; in July. This free technology event focused on open source innovations, with sessions presented by elite Red Hat technologists.&lt;/p&gt; &lt;p&gt;In this session, &lt;a href="https://developers.redhat.com/blog/author/kameshsampath/"&gt;Kamesh Sampath&lt;/a&gt; shows how to apply common Enterprise Integration Patterns (EIP) with Apache Camel, &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes, and Red Hat OpenShift&lt;/a&gt;. You will see how the new Camel K framework helps in deploying Camel DSL code as &amp;#8220;integrations&amp;#8221; in Kubernetes/OpenShift.&lt;span id="more-624787"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Watch the complete presentation:&lt;/p&gt; &lt;p&gt;&lt;iframe src="https://www.youtube.com/embed/4Xuax4s-LIc" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;h3&gt;Learn more&lt;/h3&gt; &lt;p&gt;Join us at an upcoming&lt;a href="https://developers.redhat.com/events/"&gt; developer event&lt;/a&gt;, and see our collection of&lt;a href="https://developers.redhat.com/devnation/?page=0"&gt; past DevNation Live tech talks&lt;/a&gt;&lt;a href="https://developers.redhat.com/events/"&gt;.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F22%2Fcloud-native-integration-with-kubernetes-and-camel-k%2F&amp;#38;linkname=Cloud-native%20integration%20with%20Kubernetes%20and%20Camel%20K" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F22%2Fcloud-native-integration-with-kubernetes-and-camel-k%2F&amp;#38;linkname=Cloud-native%20integration%20with%20Kubernetes%20and%20Camel%20K" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F22%2Fcloud-native-integration-with-kubernetes-and-camel-k%2F&amp;#38;linkname=Cloud-native%20integration%20with%20Kubernetes%20and%20Camel%20K" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F22%2Fcloud-native-integration-with-kubernetes-and-camel-k%2F&amp;#38;linkname=Cloud-native%20integration%20with%20Kubernetes%20and%20Camel%20K" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F22%2Fcloud-native-integration-with-kubernetes-and-camel-k%2F&amp;#38;linkname=Cloud-native%20integration%20with%20Kubernetes%20and%20Camel%20K" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F22%2Fcloud-native-integration-with-kubernetes-and-camel-k%2F&amp;#38;linkname=Cloud-native%20integration%20with%20Kubernetes%20and%20Camel%20K" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F22%2Fcloud-native-integration-with-kubernetes-and-camel-k%2F&amp;#38;linkname=Cloud-native%20integration%20with%20Kubernetes%20and%20Camel%20K" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F22%2Fcloud-native-integration-with-kubernetes-and-camel-k%2F&amp;#038;title=Cloud-native%20integration%20with%20Kubernetes%20and%20Camel%20K" data-a2a-url="https://developers.redhat.com/blog/2019/11/22/cloud-native-integration-with-kubernetes-and-camel-k/" data-a2a-title="Cloud-native integration with Kubernetes and Camel K"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/11/22/cloud-native-integration-with-kubernetes-and-camel-k/"&gt;Cloud-native integration with Kubernetes and Camel K&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/AzTPzACP1HY" height="1" width="1" alt=""/&gt;</content><summary>Our first DevNation Live regional event was held in Bengaluru, India in July. This free technology event focused on open source innovations, with sessions presented by elite Red Hat technologists. In this session, Kamesh Sampath shows how to apply common Enterprise Integration Patterns (EIP) with Apache Camel, Kubernetes, and Red Hat OpenShift. You will see how the new Camel K framework helps in d...</summary><dc:creator>Editorial Team</dc:creator><dc:date>2019-11-22T08:00:57Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/11/22/cloud-native-integration-with-kubernetes-and-camel-k/</feedburner:origLink></entry><entry><title>This Week in JBoss, 21th November 2019 - JCliff: Wildfly under Ansible control!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/lyWmLMKe3E8/this-week-in-jboss-21th-november-2019-jcliff-wildfly-under-ansible-control" /><category term="AMQ" scheme="searchisko:content:tags" /><category term="ansible" scheme="searchisko:content:tags" /><category term="byteman" scheme="searchisko:content:tags" /><category term="Devoxx" scheme="searchisko:content:tags" /><category term="EAP" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_weeklyeditorial" scheme="searchisko:content:tags" /><category term="infinispan" scheme="searchisko:content:tags" /><category term="jboss-tools" scheme="searchisko:content:tags" /><category term="jcliff" scheme="searchisko:content:tags" /><category term="keycloak" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="narayana" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="Operators" scheme="searchisko:content:tags" /><category term="quarkus" scheme="searchisko:content:tags" /><category term="Red Hat Fuse" scheme="searchisko:content:tags" /><author><name>Romain Pelisse</name></author><id>searchisko:content:id:jbossorg_blog-this_week_in_jboss_21th_november_2019_jcliff_wildfly_under_ansible_control</id><updated>2019-11-21T18:35:28Z</updated><published>2019-11-21T18:35:28Z</published><content type="html">&lt;!-- [DocumentBodyStart:d1d3494f-7f60-4fff-b6d2-a3843ca0d12b] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;p&gt;&lt;em&gt;Our last editorial was all about Quarkus, the project having just released its version 1.0. Of course, this issue will still feature of lot of news about the latest and brightest baby of the JBoss community. But I also wanted to bring up again a project have been heavily involved: JCliff and its Ansible integration. And I'm going to shamelessly used this editorial to promote it a bit &lt;span aria-label="Happy" class="emoticon_happy emoticon-inline" style="height:16px;width:16px;"&gt;&lt;/span&gt; !&lt;br/&gt;&lt;/em&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/10/Java-Jcliff.jpg"&gt;&lt;img alt="" class="image-1 jive-image" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/Java-Jcliff.jpg" style="width: 620px; height: 343px; display: block; margin-left: auto; margin-right: auto;"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;JCliff - Putting Wildfly under Ansible control&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;So what is JCliff? JCliff is a small Java tool written to help integrate Wildfly into Puppet. It&amp;#8217;s basically a layer between the JBoss CLI and the configuration management tool. Indeed, Puppet, like Ansible are working on &lt;strong&gt;state&lt;/strong&gt;. They both check that the target, in this case an instance of Widfly, is in the correct state. If not, the tool will correct the issue and ensure the system is in the proper state. JCliff simply turn the question &amp;ldquo;is this in the appropriate state&amp;#8221; into a series of JBoss CLI queries. It also does the same when the configuration management tool asks to correct the state. In the last year, we&amp;#8217;ve worked hard into integrating JCliff inside Ansible, so people using it, can be fine-tuned and automated, as much as possible, their Wildfly configuration and deployment. Please, checkout our article on &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/11/06/managing-jboss-eap-wildfly-using-jcliff/" rel="nofollow"&gt;Managing JBoss EAP/Wildfly using Jcliff&lt;/a&gt;, if you want to know more about it!&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p style="font-size: 0.9rem; font-style: italic;"&gt;&lt;a href="https://live.staticflickr.com/3345/3190647471_38d04ef9f5.jpg"&gt;&lt;img alt="Reflection Nebula NGC 1999" src="https://live.staticflickr.com/3345/3190647471_38d04ef9f5.jpg" style="display: block; margin-left: auto; margin-right: auto;"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p style="font-size: 0.9rem; font-style: italic; text-align: center;"&gt;&lt;a class="jive-link-external-small" href="https://www.flickr.com/photos/34168865@N08/3190647471" rel="nofollow"&gt;"Reflection Nebula NGC 1999"&lt;/a&gt;&lt;span&gt; by &lt;a class="jive-link-external-small" href="https://www.flickr.com/photos/34168865@N08" rel="nofollow"&gt;Hubble Heritage&lt;/a&gt;&lt;/span&gt; is licensed under &lt;a class="jive-link-external-small" href="https://creativecommons.org/licenses/by-sa/2.0/?ref=ccsearch&amp;amp;atype=html" rel="nofollow"&gt;CC BY-SA 2.0&lt;/a&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px; text-align: center;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Quarkus&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;While I'm (rightfully) proud of our integration of Wildfly for Ansible, the fact remains that the current star of the JBoss ecosystem is, without a doubt, Quarkus. You don't have to take our word for it, check out &lt;a class="jive-link-external-small" href="https://twitter.com/burrsutter/status/1197223667635240960" rel="nofollow"&gt;Thoughtswork thinks about Quarkus&lt;/a&gt;! If you have not yet checked out Quarkus, the recent &lt;a class="jive-link-external-small" href="https://quarkus.io/blog/announcing-quarkus-1-0/" rel="nofollow"&gt;release of the 1.0&lt;/a&gt; is the perfect opportunity to do so.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Why should you? Because any web Java developer or JEE developer needs to! By the way, if you are looking for an easy entry point, just follow this tutorial on &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/11/07/quarkus-modernize-helloworld-jboss-eap-quickstart-part-1/" rel="nofollow"&gt;Quarkus: Modernize "helloworld" JBoss EAP quickstart, Part 1&lt;/a&gt;&lt;/p&gt;&lt;p&gt;and its follow-up &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/11/08/quarkus-modernize-helloworld-jboss-eap-quickstart-part-2/" rel="nofollow"&gt;Quarkus: Modernize "helloworld" JBoss EAP quickstart, Part 2.&lt;/a&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;If you are already on board with Quarkus, then maybe take a look to this recent article on &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/11/18/how-quarkus-brings-imperative-and-reactive-programming-together/" rel="nofollow"&gt;How Quarkus brings imperative and reactive programming together&lt;/a&gt;, I'm pretty sure you might find it interesting.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Kubernetes&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;The last two weeks have seen a lot of interesting content about Kubernetes being released! The first one that caught our eyes is this one on &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/11/12/plumbing-kubernetes-ci-cd-with-tekton/" rel="nofollow"&gt;Plumbing Kubernetes CI/CD with Tekton.&lt;/a&gt; Another one worth mentioning is this article on &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/11/12/using-the-red-hat-openshift-tuned-operator-for-elasticsearch/" rel="nofollow"&gt;Using the Red Hat OpenShift tuned Operator for Elasticsearch. &lt;/a&gt;Both are quite intriguing and discuss some very cool use cases.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Techbytes&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Enough about Quarkus and Kubernetes for now, let's take a look at what else the JBoss community has been up to! First all, let us recommend to you this article on &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/11/14/tracing-kubernetes-applications-with-jaeger-and-eclipse-che/" rel="nofollow"&gt;Tracing Kubernetes applications with Jaeger and Eclipse Che&lt;/a&gt;, because this kind of technique might be quite handy someday and it's a good read. Next, less "debug-oriented" and more "let's do cool things", comes this other article on&amp;#160; &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/11/11/autoscaling-red-hat-fuse-applications-with-openshift/" rel="nofollow"&gt;OpenShift autoscaling Red Hat Fuse&lt;/a&gt; followed closely by &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/11/21/event-based-microservices-with-red-hat-amq-streams/" rel="nofollow"&gt;Event-based microservices with Red Hat AMQ Streams.&lt;/a&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Evangelist's Corner&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;As always, our very own Eric D. Schabell has been releasing material in the past few weeks. Noteworthy is his webinar on &lt;a class="jive-link-external-small" href="http://www.schabell.org/2019/11/blueprint-for-omnichannel-integration-architecture-webinar.html" rel="nofollow"&gt;Blueprint for omnichannel integration architecture&lt;/a&gt;, but also his tutorial on &lt;a class="jive-link-external-small" href="https://www.schabell.org/2019/11/how-to-setup-openshift-container-platform-in-minutes.html" rel="nofollow"&gt;How to set up OpenShift Container Platform on your local machine in minutes.&lt;/a&gt; Also worth mentioning in this section is the &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/kogito_deep_dive_video_from_devoxx" rel="nofollow"&gt;Kogito deep dive video from Devoxx.&lt;/a&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Releases, releases, releases...&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://www.keycloak.org/2019/11/keycloak-800-released.html" rel="nofollow"&gt;Keycloak - Blog - Keycloak 8.0.0 released&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://infinispan.org/blog/2019/11/18/infinispan-1010beta1/" rel="nofollow"&gt;Infinispan 10.1.0.Beta1 - Infinispan&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="http://bytemanblog.blogspot.com/2019/11/byteman-409-has-been-released.html" rel="nofollow"&gt;Byteman Blog: Byteman 4.0.9 has been released&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="http://jbossts.blogspot.com/2019/11/narayana-5100final-released.html" rel="nofollow"&gt;Narayana team blog: Narayana 5.10.0.Final released&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="http://tools.jboss.org/documentation/whatsnew/jbosstools/4.13.0.Final.html" rel="nofollow"&gt;JBoss Tools 4.13.0&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://developers.redhat.com/products/codeready-studio/overview" rel="nofollow"&gt;Red Hat CodeReady Studio 12.13&lt;/a&gt; for Eclipse 2019-09&lt;/li&gt;&lt;/ul&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;D&amp;eacute;caf&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Enough about Java stuff? Want to hear about JBoss community-related news outside of the Javasphere? Well, did you hear about this supercool integration between Wildfly and Ansible using something called JCliff? OK, enough shameless plug. Even I can see this one is just too much&amp;hellip;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;&lt;em&gt;That's all for another edition of the JBoss Editorial, please join us again for more exciting development from the JBoss Communities.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:d1d3494f-7f60-4fff-b6d2-a3843ca0d12b] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/lyWmLMKe3E8" height="1" width="1" alt=""/&gt;</content><summary>Our last editorial was all about Quarkus, the project having just released its version 1.0. Of course, this issue will still feature of lot of news about the latest and brightest baby of the JBoss community. But I also wanted to bring up again a project have been heavily involved: JCliff and its Ansible integration. And I'm going to shamelessly used this editorial to promote it a bit !     JCliff ...</summary><dc:creator>Romain Pelisse</dc:creator><dc:date>2019-11-21T18:35:28Z</dc:date><feedburner:origLink>https://developer.jboss.org/blogs/weekly-editorial/2019/11/21/this-week-in-jboss-21th-november-2019-jcliff-wildfly-under-ansible-control</feedburner:origLink></entry><entry><title>Event-based microservices with Red Hat AMQ Streams</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/e2nifu1IK9I/" /><category term="Apache Kafka" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="Red Hat AMQ" scheme="searchisko:content:tags" /><category term="Red Hat AMQ Streams" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Application Runtimes" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><author><name>chgan</name></author><id>searchisko:content:id:jbossorg_blog-event_based_microservices_with_red_hat_amq_streams</id><updated>2019-11-21T08:00:38Z</updated><published>2019-11-21T08:00:38Z</published><content type="html">&lt;p&gt;As part of &lt;a href="https://www.redhat.com/en/technologies/jboss-middleware/amq" target="_blank" rel="noopener noreferrer"&gt;Red Hat&amp;#8217;s AMQ&lt;/a&gt; offerings, Red Hat offers a Kafka-based event streaming solution both for traditional deployment and microservices-based deployment branded as &lt;a href="https://developers.redhat.com/blog/2019/10/03/deploy-red-hat-amq-streams-and-fuse-on-openshift-container-platform-4/"&gt;Red Hat AMQ Streams&lt;/a&gt;. The &lt;a href="https://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt; AMQ Streams deployment option is based on &lt;a href="https://strimzi.io/" target="_blank" rel="noopener noreferrer"&gt;Strimzi,&lt;/a&gt; an open source tool that makes Kafka deployment as a container on a Kubernetes platform easy because most of the deployment prerequisites are automated with the OpenShift &lt;a href="https://www.redhat.com/en/blog/introducing-operator-framework-building-apps-kubernetes"&gt;Operator Framework&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;In this article, we look at how to deploy Apache Kafka on Red Hat OpenShift 4, using reasonable sample microservice applications to showcase the endless possibility of innovation brought by OpenShift and Kafka.&lt;span id="more-650207"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class="wp-image-650267 size-large aligncenter" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screenshot-2019-11-08-at-11.52.29-AM-1024x540.png" alt="AMQ Streams on OpenShift" width="640" height="338" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screenshot-2019-11-08-at-11.52.29-AM-1024x540.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screenshot-2019-11-08-at-11.52.29-AM-300x158.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screenshot-2019-11-08-at-11.52.29-AM-768x405.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;p style="text-align: center;"&gt;&lt;em&gt;Figure 1: Our deployment environment.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Figure 1 illustrates the environment we will deploy on OpenShift with a number of microservices, including:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The &lt;strong&gt;Account Balance Service&lt;/strong&gt; provides information on the account balance, which has its own MongoDB database services.&lt;/li&gt; &lt;li&gt;The&lt;strong&gt; Credit Service&lt;/strong&gt; performs credit transfer between accounts, storing the credit data in the &lt;code&gt;credit&lt;/code&gt; Kafka topic.&lt;/li&gt; &lt;li&gt;The &lt;strong&gt;Event Correlator &lt;/strong&gt;listens to the &lt;code&gt;credit&lt;/code&gt; topic, performs the necessary adjustment to the account balance, and updates the changes to the Account Balance Service via the REST API. At the same time, it sends the outcome of this process as a credit response to the Kafka topic &lt;code&gt;credit-response&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;MongoDB Kafka Connect&lt;/strong&gt; listens to the content in the &lt;code&gt;credit-response&lt;/code&gt; topic and streams this information to the &lt;strong&gt;Credit Response DB&lt;/strong&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Install AMQ Streams on Red Hat OpenShift&lt;/h2&gt; &lt;p&gt;AMQ Streams installation is pretty straightforward on Red Hat OpenShift. The only issue I faced was configuring MongoDB Kafka Connect, and that was mostly due to a lack of detailed documentation and a bug in Kafka Connect. All of these issues are now structurally documented as the following:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Download the YAML installation files from the &lt;a href="https://access.redhat.com/jbossnetwork/restricted/listSoftware.html?downloadType=distributions&amp;#38;product=jboss.amq.streams" target="_blank" rel="noopener noreferrer"&gt;Red Hat Access website&lt;/a&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;Note: &lt;/strong&gt;We are installing these AMQ Streams using cluster admin. AMQ Streams includes several custom resources. By default, permission to create, edit, and delete these resources is limited to OpenShift cluster administrators. If you want to allow non-cluster administrators to manage AMQ Streams resources, you must assign them the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.5/html/using_amq_streams_on_openshift/getting-started-str#assembly-getting-started-strimzi-admin-str" target="_blank" rel="noopener noreferrer"&gt;Strimzi Administrator role&lt;/a&gt;.&lt;/p&gt; &lt;ol start="2"&gt; &lt;li&gt;Deploy the Kafka cluster using the Kafka Operator, which can watch Kafka resources for single and multiple namespaces. In our case, we deploy the Operator to watch for a single namespace. Once you download and unzip the installation files, navigate to the root folder, which contains two folders: &lt;code&gt;examples&lt;/code&gt; and &lt;code&gt;install&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Run the following from the command line to make changes to the provided YAML files for our single OpenShift namespace deployment:&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;On Linux:&lt;/p&gt; &lt;pre&gt;$ sed -i 's/namespace: .*/namespace: my-kafka-example/' install/cluster-operator/*RoleBinding*.yaml&lt;/pre&gt; &lt;p&gt;On macOS:&lt;/p&gt; &lt;pre&gt;$ sed -i '' 's/namespace: .*/namespace: my-kafka-example/' install/cluster-operator/*RoleBinding*.yaml&lt;/pre&gt; &lt;ol start="4"&gt; &lt;li&gt;Run the following command to deploy the Operator once the namespace is changed:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc apply -f install/cluster-operator -n my-kafka-example&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You can also configure the Kafka Operator to watch for all namespaces. Please refer to the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.5/html/using_amq_streams_on_openshift/getting-started-str#deploying-cluster-operator-to-watch-whole-cluster-str" target="_blank" rel="noopener noreferrer"&gt;documentation&lt;/a&gt; for details.&lt;/p&gt; &lt;ol start="5"&gt; &lt;li&gt;Deploy the Kafka cluster once the Kafka Operator is deployed. There are two options: ephemeral and persistent. We will deploy a persistent Kafka cluster. Begin by opening the &lt;code&gt;examples/kafka/kafka-persistent.yaml&lt;/code&gt; file and changing the Kafka cluster name in the &lt;code&gt;Kafka.metadata.name&lt;/code&gt; property as follows:&lt;/li&gt; &lt;/ol&gt; &lt;div&gt; &lt;pre style="padding-left: 40px;"&gt;apiVersion: kafka.strimzi.io/v1beta1 kind: Kafka metadata:  name: my-kafka-cluster # ...&lt;/pre&gt; &lt;ol start="6"&gt; &lt;li&gt;Configure the Topic Operator as the following in the same &lt;code&gt;kafka-persistent.yaml&lt;/code&gt; file as before, in order to enable auto-creation of the Kafka topics configured in the applications:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;entityOperator:    topicOperator:      watchedNamespace: my-kafka-example      reconciliationIntervalSeconds: 90      zookeeperSessionTimeoutSeconds: 20      topicMetadataMaxAttempts: 6       image: registry.redhat.io/amq7/amq-streams-operator:1.3.0&lt;/pre&gt; &lt;ol start="7"&gt; &lt;li&gt;Run the following command to deploy the Kafka cluster:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;oc apply -f examples/kafka/kafka-persistent.yaml&lt;/pre&gt; &lt;ol start="8"&gt; &lt;li&gt;Deploy and run the following sample Kafka producer:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;oc run kafka-producer -ti --image=registry.redhat.io/amq7/amq-streams-kafka-23:1.3.0 --rm=true --restart=Never -- bin/kafka-console-producer.sh --broker-list kafka-cluster-kafka-bootstrap:9092 --topic my-topic&lt;/pre&gt; &lt;ol start="9"&gt; &lt;li&gt;Deploy and run the following sample Kafka consumer:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;oc run kafka-consumer -ti --image=registry.redhat.io/amq7/amq-streams-kafka-23:1.3.0 --rm=true --restart=Never -- bin/kafka-console-consumer.sh --bootstrap-server kafka-cluster-kafka-bootstrap:9092 --topic my-topic --from-beginning&lt;/pre&gt; &lt;ol start="10"&gt; &lt;li&gt;Verify that the Kafka cluster is working as expected once all of the pods and resources are ready, which means seeing if you can send messages from the producer to the consumer.&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Deploy sample application dependencies&lt;/h2&gt; &lt;p&gt;Due to AMQ Streams, brokers are not accessible directly outside of the namespace where they are deployed. We will deploy all of our sample applications in the same namespace as the Kafka cluster. This issue is the same for all Kafka brokers deployed as containers, and this is not a limitation of OpenShift. All external connections are handled and routed by the Kafka bootstrap component.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you wish to access the brokers externally, please refer to this &lt;a href="https://developers.redhat.com/blog/2019/06/10/accessing-apache-kafka-in-strimzi-part-3-red-hat-openshift-routes/"&gt;article&lt;/a&gt; on how to enable this option.&lt;/p&gt; &lt;h3&gt;Deploy MongoDB&lt;/h3&gt; &lt;div&gt; &lt;div&gt;This is our Credit Response database. Run the following command to deploy MongoDB using the provided template:&lt;/div&gt; &lt;pre&gt;oc new-app -f https://raw.githubusercontent.com/chengkuangan/creditresponsemongodb/master/mongodb-deployment-template.yaml&lt;/pre&gt; &lt;p&gt;During the time this article was written and due to the hardcoded database authentication source, I received the following error (&lt;code&gt;source='admin'&lt;/code&gt;) in the Kafka Connect container log when Kafka Connect was trying to send data to MongoDB:&lt;/p&gt; &lt;pre&gt;2019-11-07 12:23:07,617 INFO Cluster created with settings {hosts=[creditresponse:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} (org.mongodb.driver.cluster) [task-thread-mongodb-sink-0] 2019-11-07 12:23:07,842 INFO Cluster description not yet available. Waiting for 30000 ms before timing out (org.mongodb.driver.cluster) [task-thread-mongodb-sink-0] 2019-11-07 12:23:07,861 INFO Opened connection [connectionId{localValue:1, serverValue:220}] to creditresponse:27017 (org.mongodb.driver.connection) [cluster-ClusterId{value='5dc40cab2efd9074c7742e33', description='null'}-creditresponse:27017] 2019-11-07 12:23:07,863 INFO Monitor thread successfully connected to server with description ServerDescription{address=creditresponse:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 2, 10]}, minWireVersion=0, maxWireVersion=4, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=null, roundTripTimeNanos=1014605} (org.mongodb.driver.cluster) [cluster-ClusterId{value='5dc40cab2efd9074c7742e33', description='null'}-creditresponse:27017] 2019-11-07 12:23:07,892 INFO Closed connection [connectionId{localValue:2}] to creditresponse:27017 because there was a socket exception raised by this connection. (org.mongodb.driver.connection) [task-thread-mongodb-sink-0] 2019-11-07 12:23:07,894 ERROR Error on mongodb operation (com.mongodb.kafka.connect.sink.MongoSinkTask) [task-thread-mongodb-sink-0] com.mongodb.MongoSecurityException: Exception authenticating MongoCredential{mechanism=SCRAM-SHA-1, userName='creditresponse', source='admin', password=&amp;#60;hidden&amp;#62;, mechanismProperties={}}   at com.mongodb.internal.connection.SaslAuthenticator.wrapException(SaslAuthenticator.java:173)&lt;/pre&gt; &lt;p&gt;To work around this problem, perform &lt;code&gt;oc rsh&lt;/code&gt; into the MongoDB pod to create a new &lt;code&gt;creditresponse&lt;/code&gt; user account with the following details:&lt;/p&gt; &lt;pre&gt;mongo --port 27017 -u admin -p creditresponse --authenticationDatabase admin use admin db.runCommand({createRole:"listDatabases",privileges:[{resource:{cluster:true}, actions:["listDatabases"]}],roles:[]}) db.createUser({ "user" : "creditresponse", "pwd" : "creditresponse",    "roles" : [        {            "role" : "listDatabases",            "db" : "admin"        },        {            "role" : "readWrite",            "db" : "creditresponse"        },        {            "role" : "read",            "db" : "local"        }    ] })&lt;/pre&gt; &lt;/div&gt; &lt;h3&gt;Deploy and configure MongoDB Kafka Connect&lt;/h3&gt; &lt;p&gt;AMQ Streams Kafka Connect only comes with &lt;code&gt;FileStreamSourceConnector&lt;/code&gt; and &lt;code&gt;FileStreamSinkConnector&lt;/code&gt;. In order to deploy MongoDB Kafka Connect, we need to build the container image with the MongoDB Kafka Connect JAR file and the Red Hat-supported AMQ Streams base image:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Proceed to create the necessary Dockerfile with the following content:&lt;/li&gt; &lt;/ol&gt; &lt;div&gt; &lt;pre style="padding-left: 40px;"&gt; FROM registry.redhat.io/amq7/amq-streams-kafka-23:1.3.0 USER root:root COPY ./mongo-plugins/ /opt/kafka/plugins/ USER kafka:kafka&lt;/pre&gt; &lt;ol start="2"&gt; &lt;li&gt;Download the MongoDB Kafka Connect JAR files from the &lt;a href="https://www.mongodb.com/kafka-connector" target="_blank" rel="noopener noreferrer"&gt;MongoDB website&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Unzip and copy the JAR file to the &lt;code&gt;mongo-plugins&lt;/code&gt; folder.&lt;/li&gt; &lt;li&gt;Make sure you have a valid Red Hat account in order to log in and access &lt;code&gt;registry.redhat.io&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Build the image:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;docker login registry.redhat.io docker build -t chengkuan/amq-streams-kafka-connect-23:1.3.0&lt;/pre&gt; &lt;ol start="6"&gt; &lt;li&gt;Change &lt;code&gt;kafka-connect.yaml&lt;/code&gt; with the following &lt;code&gt;spec.image&lt;/code&gt;,&lt;em&gt; &lt;code&gt;spec.bootstrapServers&lt;/code&gt;&lt;/em&gt;, and &lt;code&gt;spec.tls.trustedCertificates.secretName&lt;/code&gt;. Take note that the port number for &lt;em&gt;&lt;code&gt;spec.bootstrapServers&lt;/code&gt;&lt;/em&gt; is 9093, which is the default &lt;code&gt;clienttls&lt;/code&gt; port:&lt;/li&gt; &lt;/ol&gt; &lt;div&gt; &lt;pre style="padding-left: 40px;"&gt;apiVersion: kafka.strimzi.io/v1beta1 kind: KafkaConnect metadata:  name: mongodb-connect-cluster spec:  version: 2.3.0  replicas: 1  bootstrapServers: kafka-cluster-kafka-bootstrap:9093  tls:    trustedCertificates:      - secretName: kafka-cluster-cluster-ca-cert        certificate: ca.crt   image: docker.io/chengkuan/amq-streams-kafka-connect-23:1.3.0&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;ol start="7"&gt; &lt;li&gt;Deploy Kafka Connect:&lt;/li&gt; &lt;/ol&gt; &lt;div&gt; &lt;pre style="padding-left: 40px;"&gt;oc apply -f examples/kafka-connect/kafka-connect.yaml&lt;/pre&gt; &lt;div&gt; &lt;ol start="8"&gt; &lt;li&gt;Port forward from a local PC to OpenShift&amp;#8217;s connect API service because Kafka Connect&amp;#8217;s pod is not accessible externally:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;oc port-forward service/mongodb-connect-cluster-connect-api 8083:8083&lt;/pre&gt; &lt;ol start="9"&gt; &lt;li&gt;Run the following using &lt;code&gt;curl&lt;/code&gt; or a web browser to verify that the MongoDB Connect plugin loaded successfully:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;curl http://localhost:8083/connector-plugins&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;You will see that the MongoDB Connect plugin is listed:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;[{"class":"com.mongodb.kafka.connect.MongoSinkConnector","type":"sink","version":"0.2"},{"class":"com.mongodb.kafka.connect.MongoSourceConnector","type":"source","version":"0.2"},{"class":"org.apache.kafka.connect.file.FileStreamSinkConnector","type":"sink","version":"2.3.0.redhat-00003"},{"class":"org.apache.kafka.connect.file.FileStreamSourceConnector","type":"source","version":"2.3.0.redhat-00003"}]&lt;/pre&gt; &lt;/div&gt; &lt;p&gt;To configure MongoDB Kafka Connect, download &lt;a href="https://raw.githubusercontent.com/chengkuangan/creditresponsemongodb/master/connect-mongodb-sink.json" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;connect-mongodb-sink.json&lt;/code&gt;&lt;/a&gt; and modify the following accordingly:&lt;/p&gt; &lt;pre&gt;{ "name": "mongodb-sink", "config": { "connector.class": "com.mongodb.kafka.connect.MongoSinkConnector", "tasks.max": 1, "topics": "credit-response", "connection.uri": "mongodb://creditresponse:creditresponse@creditresponse:27017", "database": "creditresponse", "collection": "response", "key.converter": "org.apache.kafka.connect.json.JsonConverter", "key.converter.schemas.enable": false, "value.converter": "org.apache.kafka.connect.json.JsonConverter", "value.converter.schemas.enable": false, "max.num.retries": 3 } }&lt;/pre&gt; &lt;p&gt;Next, post to the Kafka Connect REST API:&lt;/p&gt; &lt;pre&gt;curl -d connect-mongodb-sink.json -H "Content-Type: application/json" -X POST http://localhost:8083/connectors&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; At the time this was written, I could not &lt;code&gt;POST&lt;/code&gt; the content successfully to Kafka Connect using the &lt;code&gt;curl&lt;/code&gt; command due to a JSON formatting error. However, I can &lt;code&gt;POST&lt;/code&gt; the same content without errors using Postman.&lt;/p&gt; &lt;/div&gt; &lt;p&gt;Finally, run the following &lt;code&gt;curl&lt;/code&gt; command to verify the configuration:&lt;/p&gt; &lt;/div&gt; &lt;pre&gt;curl http://localhost:8083/connectors/mongodb-sink&lt;/pre&gt; &lt;p&gt;The result:&lt;/p&gt; &lt;pre&gt;{ "name": "mongodb-sink", "config": { "connector.class": "com.mongodb.kafka.connect.MongoSinkConnector", "key.converter.schemas.enable": "false", "database": "creditresponse", "tasks.max": "1", "topics": "credit-response", "max.num.retries": "3", "connection.uri": "mongodb://creditresponse:creditresponse@creditresponse:27017", "value.converter.schemas.enable": "false", "name": "mongodb-sink", "collection": "response", "value.converter": "org.apache.kafka.connect.json.JsonConverter", "key.converter": "org.apache.kafka.connect.json.JsonConverter" }, "tasks": [ { "connector": "mongodb-sink", "task": 0 } ], "type": "sink" }&lt;/pre&gt; &lt;h3&gt;Deploy the Account Balance Service application&lt;/h3&gt; &lt;p&gt;Run the following command to deploy the pods:&lt;/p&gt; &lt;pre&gt;oc new-app https://raw.githubusercontent.com/chengkuangan/accountbalance/master/templates/deployment-templates.yaml&lt;/pre&gt; &lt;h3&gt;Deploy the Credit Service application&lt;/h3&gt; &lt;p&gt;Run the following command to deploy the Credit Service. Ensure that &lt;code&gt;KAFKA_BOOTSTRAP_SERVER&lt;/code&gt; points to the correct server:&lt;/p&gt; &lt;pre&gt;oc new-app https://raw.githubusercontent.com/chengkuangan/creditservice/master/templates/creditservice.json -p KAFKA_BOOTSTRAP_SERVER=kafka-cluster-kafka-bootstrap:9092&lt;/pre&gt; &lt;h3&gt;Deploy the Event Correlator Service&lt;/h3&gt; &lt;div&gt;Run the following command to deploy the Event Correlator Service. Ensure that &lt;code&gt;KAFKA_BOOTSTRAP_SERVER&lt;/code&gt; points to the correct server:&lt;/div&gt; &lt;pre&gt;oc new-app -f https://raw.githubusercontent.com/chengkuangan/eventcorrelator/master/templates/deployment-templates.yaml -p KAFKA_BOOTSTRAP_SERVER=kafka-cluster-kafka-bootstrap:9092&lt;/pre&gt; &lt;h2&gt;Watch the application in action&lt;/h2&gt; &lt;div&gt;Now, let us use our application. Create account balance records:&lt;/div&gt; &lt;pre&gt;curl -H "Content-Type: application/json" -X POST http://accountbalance-my-kafka-example.apps.demo.ocp.internal/ws/pg/balance -d '{"accountId": "20191108-MY-00000001", "balance": 500.00, "lastUpdatedDate": 1563178274158 }' curl -H "Content-Type: application/json" -X POST http://accountbalance-my-kafka-example.apps.demo.ocp.internal/ws/pg/balance -d '{"accountId": "20191108-MY-00000002", "balance": 700.00, "lastUpdatedDate": 1563178274158 }'&lt;/pre&gt; &lt;p&gt;Query the account balance entries created above:&lt;/p&gt; &lt;pre&gt;curl http://accountbalance-my-kafka-example.apps.demo.ocp.internal/ws/pg/balance/all&lt;/pre&gt; &lt;p&gt;The result:&lt;/p&gt; &lt;pre&gt;[ { "_id":"5dc52069a3c1080001ebd539", "accountId":"20191108-MY-00000001", "balance":500.0, "lastUpdatedDate":1563178274158 }, { "_id":"5dc52076a3c1080001ebd53a", "accountId":"20191108-MY-00000002", "balance":700.0, "lastUpdatedDate":1563178274158 } ]&lt;/pre&gt; &lt;p&gt;Perform a credit transfer:&lt;/p&gt; &lt;pre&gt;curl -H "Content-Type: application/json" -X POST http://creditservice-my-kafka-example.apps.demo.ocp.internal/ws/pg/credits -d '{"amount": 10.50, "sourceAccount": "20191108-MY-00000001", "targetAccount": "20191108-MY-00000002"}'&lt;/pre&gt; &lt;p&gt;Query the balance after the credit transfer:&lt;/p&gt; &lt;pre&gt;curl http://accountbalance-my-kafka-example.apps.demo.ocp.internal/ws/pg/balance/all&lt;/pre&gt; &lt;p&gt;The result:&lt;/p&gt; &lt;pre&gt;[ { "_id":"5dc52069a3c1080001ebd539", "accountId":"20191108-MY-00000001", "balance":489.5,"lastUpdatedDate":1573200543543 }, { "_id":"5dc52076a3c1080001ebd53a", "accountId":"20191108-MY-00000002", "balance":710.5, "lastUpdatedDate":1573200543543 } ]&lt;/pre&gt; &lt;p&gt;Perform &lt;code&gt;oc rsh&lt;/code&gt; into the Credit Response MongoDB. Use &lt;code&gt;db.response.find()&lt;/code&gt; to see that the credit response is captured:&lt;/p&gt; &lt;pre&gt;mongo --port 27017 -u admin -p creditresponse --authenticationDatabase admin &amp;#62;use creditresponse switched to db creditresponse &amp;#62;show collections response &amp;#62;db.response.find()&lt;/pre&gt; &lt;p&gt;Result:&lt;/p&gt; &lt;pre&gt;{ "_id" : ObjectId("5dc523f536d41402601d01a4"), "sourceAccountRecordId" : "5dc52069a3c1080001ebd539", "targetAccountRecordId" : "5dc52076a3c1080001ebd53a", "sourceAccountId" : "20191108-MY-00000001", "targetAccountId" : "20191108-MY-00000002", "sourceAccountBalance" : 489.5, "targetAccountBalance" : 710.5, "creditRecordId" : "ykvlkqk2puzc5u", "creditAmount" : 10.5, "transactionDate" : NumberLong("1573200543543") }&lt;/pre&gt; &lt;h3&gt;References&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.5/html/using_amq_streams_on_openshift/" target="_blank" rel="noopener noreferrer"&gt;Red Hat AMQ Streams on OpenShift documentation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://kafka.apache.org/documentation/#connect" target="_blank" rel="noopener noreferrer"&gt;Apache Kafka Connect documentation&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F21%2Fevent-based-microservices-with-red-hat-amq-streams%2F&amp;#38;linkname=Event-based%20microservices%20with%20Red%20Hat%20AMQ%20Streams" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F21%2Fevent-based-microservices-with-red-hat-amq-streams%2F&amp;#38;linkname=Event-based%20microservices%20with%20Red%20Hat%20AMQ%20Streams" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F21%2Fevent-based-microservices-with-red-hat-amq-streams%2F&amp;#38;linkname=Event-based%20microservices%20with%20Red%20Hat%20AMQ%20Streams" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F21%2Fevent-based-microservices-with-red-hat-amq-streams%2F&amp;#38;linkname=Event-based%20microservices%20with%20Red%20Hat%20AMQ%20Streams" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F21%2Fevent-based-microservices-with-red-hat-amq-streams%2F&amp;#38;linkname=Event-based%20microservices%20with%20Red%20Hat%20AMQ%20Streams" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F21%2Fevent-based-microservices-with-red-hat-amq-streams%2F&amp;#38;linkname=Event-based%20microservices%20with%20Red%20Hat%20AMQ%20Streams" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F21%2Fevent-based-microservices-with-red-hat-amq-streams%2F&amp;#38;linkname=Event-based%20microservices%20with%20Red%20Hat%20AMQ%20Streams" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F21%2Fevent-based-microservices-with-red-hat-amq-streams%2F&amp;#038;title=Event-based%20microservices%20with%20Red%20Hat%20AMQ%20Streams" data-a2a-url="https://developers.redhat.com/blog/2019/11/21/event-based-microservices-with-red-hat-amq-streams/" data-a2a-title="Event-based microservices with Red Hat AMQ Streams"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/11/21/event-based-microservices-with-red-hat-amq-streams/"&gt;Event-based microservices with Red Hat AMQ Streams&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/e2nifu1IK9I" height="1" width="1" alt=""/&gt;</content><summary>As part of Red Hat’s AMQ offerings, Red Hat offers a Kafka-based event streaming solution both for traditional deployment and microservices-based deployment branded as Red Hat AMQ Streams. The Red Hat OpenShift AMQ Streams deployment option is based on Strimzi, an open source tool that makes Kafka deployment as a container on a Kubernetes platform easy because most of the deployment prerequisites ...</summary><dc:creator>chgan</dc:creator><dc:date>2019-11-21T08:00:38Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/11/21/event-based-microservices-with-red-hat-amq-streams/</feedburner:origLink></entry><entry><title>New features in Quarkus Tools for Visual Studio Code 1.2.0</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/WA9IloC7oHg/" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="quarkus" scheme="searchisko:content:tags" /><category term="Quarkus Tools for Visual Studio Code" scheme="searchisko:content:tags" /><category term="VS Code" scheme="searchisko:content:tags" /><category term="VS Code Extensions" scheme="searchisko:content:tags" /><author><name>David Kwon</name></author><id>searchisko:content:id:jbossorg_blog-new_features_in_quarkus_tools_for_visual_studio_code_1_2_0</id><updated>2019-11-21T08:00:04Z</updated><published>2019-11-21T08:00:04Z</published><content type="html">&lt;p&gt;We are proud to present the new release of &lt;a href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-quarkus"&gt;Quarkus Tools for Visual Studio Code&lt;/a&gt;, providing a feature-rich development experience in &lt;a href="https://developers.redhat.com/blog/category/vs-code/"&gt;VS Code&lt;/a&gt; for &lt;a href="https://developers.redhat.com/topics/quarkus/"&gt;Quarkus&lt;/a&gt; application development. This release focused on introducing tooling support for Gradle projects, as well as adding new &lt;code&gt;application.properties&lt;/code&gt; language features.&lt;/p&gt; &lt;p&gt;Watch a demo of the new features:&lt;br /&gt; &lt;iframe src="https://www.youtube.com/embed/hZ_JJ9izV7s" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;h2&gt;New features&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Gradle — Generate new Quarkus project&lt;/li&gt; &lt;li&gt;Gradle — Debug Quarkus project&lt;/li&gt; &lt;li&gt;Gradle — Add extensions to a Quarkus project&lt;/li&gt; &lt;li&gt;Quick fix for unknown property name&lt;/li&gt; &lt;li&gt;Quick fix for invalid enum value&lt;/li&gt; &lt;li&gt;Quick fix for missing required properties&lt;/li&gt; &lt;li&gt;Add a glob pattern for excluding unknown property validation&lt;/li&gt; &lt;li&gt;Language feature support for logging level values&lt;/li&gt; &lt;li&gt;Documentation for default profiles&lt;/li&gt; &lt;li&gt;Improved input validation when generating a new Quarkus project&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Gradle support&lt;/h2&gt; &lt;p&gt;So far, Quarkus Tools for Visual Studio Code was geared towards Maven Quarkus projects. This release finally brings support to Gradle Quarkus projects. Moving forward, new features will be implemented with both Maven and Gradle in mind.&lt;/p&gt; &lt;h3&gt;Gradle — Generate new Quarkus project&lt;/h3&gt; &lt;p&gt;The project generation wizard now provides the option to choose between creating a Maven or a Gradle project. The rest of the wizard is the same as before. After going through the wizard, your new Maven or Gradle project will download and open automatically.&lt;/p&gt; &lt;p&gt;To open the project generation wizard, open the VS Code command palette and call the &lt;code&gt;Quarkus: Generate a Quarkus project&lt;/code&gt; command.&lt;br /&gt; &lt;img class=" alignnone size-full wp-image-653957 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/01_gradle_project_gen-1024x253.gif" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/01_gradle_project_gen.gif" alt="" width="1338" height="331" /&gt;&lt;/p&gt; &lt;h3&gt;Gradle — Debug Quarkus project&lt;/h3&gt; &lt;p&gt;The debug command will now detect whether your currently opened Quarkus project is a Maven or Gradle project, and will start the application by running the Quarkus Dev command (&lt;code&gt;mvn quarkus:dev&lt;/code&gt; for Maven, &lt;code&gt;gradle quarkusDev&lt;/code&gt; for Gradle). Once the application is running, the debugger will attach.&lt;/p&gt; &lt;p&gt;To run the debug command, open the VS Code command palette and call the &lt;code&gt;Quarkus: Debug current Quarkus project&lt;/code&gt; command.&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-full wp-image-656537 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Debug.gif" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Debug.gif" alt="" width="959" height="515" /&gt;&lt;/p&gt; &lt;h3&gt;Gradle — Add extensions to a Quarkus project&lt;/h3&gt; &lt;p&gt;The add extensions wizard now supports adding Quarkus extensions to Gradle projects.&lt;/p&gt; &lt;p&gt;To view the list of extensions to add, open the VS Code command palette and call the &lt;code&gt;Quarkus: Add extensions to current project&lt;/code&gt; command.&lt;/p&gt; &lt;p&gt;Here, the Eclipse Vert.x extension was added:&lt;br /&gt; &lt;img class=" alignnone size-full wp-image-653987 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/04_gradle_add-1024x339.gif" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/04_gradle_add.gif" alt="" width="1300" height="430" /&gt;&lt;/p&gt; &lt;p&gt;Since Eclipse Vert.x was selected, the &lt;code&gt;./gradlew addExtension --extensions="quarkus-vertx"&lt;/code&gt; command will run in the integrated terminal to add the extension:&lt;br /&gt; &lt;img class=" alignnone size-full wp-image-653997 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/05_gradle_add-1024x173.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/05_gradle_add.png" alt="" width="1345" height="227" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/05_gradle_add.png 1345w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/05_gradle_add-300x51.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/05_gradle_add-768x130.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/05_gradle_add-1024x173.png 1024w" sizes="(max-width: 1345px) 100vw, 1345px" /&gt;&lt;/p&gt; &lt;p&gt;In short, the project generation wizard can now generate Gradle projects, and the &lt;code&gt;Quarkus: Add extensions to current project&lt;/code&gt; and &lt;code&gt;Quarkus: Debug current Quarkus project&lt;/code&gt; commands work for &lt;i&gt;both&lt;/i&gt; Gradle and Maven projects.&lt;/p&gt; &lt;h2&gt;New &lt;code&gt;application.properties&lt;/code&gt; features&lt;/h2&gt; &lt;h3&gt;Quick fix for unknown property name&lt;/h3&gt; &lt;p&gt;The validation support provided by Quarkus Tools for Visual Studio Code checks for unknown property keys in your &lt;code&gt;application.properties&lt;/code&gt; file. This release brings a new Quick fix that suggests known properties for your unknown properties. This feature is kind of like autocorrect or &amp;#8220;spellcheck&amp;#8221; for your property keys.&lt;/p&gt; &lt;p&gt;To perform the Quick fix, hover over an unknown property and click&lt;em&gt; Quick Fix&lt;/em&gt; to see the proposed suggestions. Please note, the Quick fix suggestions only appear if your unknown property has a similar name to a known property.&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-full wp-image-654007 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/06_quickfix_unknown-1024x339.gif" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/06_quickfix_unknown.gif" alt="" width="1300" height="430" /&gt;&lt;/p&gt; &lt;h3&gt;Quick fix for invalid enum value&lt;/h3&gt; &lt;p&gt;Similarly, there is also a new Quick fix that suggests valid enum values. The Quick fix will either suggest all valid enum values or, if the invalid enum value is similar to a valid enum value, only the similar enum value(s) will be suggested.&lt;br /&gt; &lt;img class=" alignnone size-full wp-image-657077 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/codeactionvalue.gif" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/codeactionvalue.gif" alt="" width="826" height="286" /&gt;&lt;/p&gt; &lt;h3&gt;Quick fix for missing required properties&lt;/h3&gt; &lt;p&gt;The last new Quick fix is a Quick fix that adds all missing required properties to the &lt;code&gt;application.properties&lt;/code&gt; file. To use this feature, the required properties validation needs to be enabled, as it is disabled by default. To do so, open VS Code settings and set the &lt;em&gt;Quarkus &amp;#62; Tools &amp;#62; Validation &amp;#62; Required &amp;#62; Severity&lt;/em&gt; setting to either &lt;em&gt;Warning&lt;/em&gt; or &lt;em&gt;Error&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;Once the &lt;code&gt;application.properties&lt;/code&gt; file is open, there will be a “Missing required property” warning or error message. The corresponding Quick fix will add all missing required properties to the &lt;code&gt;application.properties&lt;/code&gt; file:&lt;br /&gt; &lt;img class=" alignnone size-full wp-image-654017 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/07_quickfix_missing-1024x453.gif" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/07_quickfix_missing.gif" alt="" width="1417" height="627" /&gt;&lt;/p&gt; &lt;h3&gt;Add a glob pattern for excluding unknown property validation&lt;/h3&gt; &lt;p&gt;This release also allows you to exclude certain properties from unknown property validation. To do this, go to VS Code settings and add a new glob pattern to the &lt;em&gt;Quarkus &amp;#62; Tools &amp;#62; Validation &amp;#62; Unknown &amp;#62; Excluded&lt;/em&gt; setting.&lt;br /&gt; &lt;img class=" alignnone size-full wp-image-654027 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/08_glob_ignore-1024x369.gif" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/08_glob_ignore.gif" alt="" width="1417" height="511" /&gt;&lt;/p&gt; &lt;p&gt;This only excludes properties matching the glob pattern from unknown property validation. Other validation such as missing equal sign validation will continue to work.&lt;br /&gt; &lt;img class=" alignnone size-full wp-image-654037 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/09_missing_equals-1024x238.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/09_missing_equals.png" alt="" width="1075" height="250" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/09_missing_equals.png 1075w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/09_missing_equals-300x70.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/09_missing_equals-768x179.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/09_missing_equals-1024x238.png 1024w" sizes="(max-width: 1075px) 100vw, 1075px" /&gt;&lt;/p&gt; &lt;p&gt;A good use case for this feature is to ignore certain MicroProfile Config annotated properties (see &lt;a href="https://github.com/redhat-developer/quarkus-ls/issues/135"&gt;quarkus-ls#135&lt;/a&gt;), which Quarkus Tools for Visual Studio Code does not recognize for the time being.&lt;/p&gt; &lt;h3&gt;Language feature support for logging level values&lt;/h3&gt; &lt;p&gt;Moving on, there is now autocompletion, documentation, validation and hover support for &lt;code&gt;java.util.logging.Level&lt;/code&gt; values. Autocompletion will provide all possible values alongside their documentation. Providing an incorrect logging level causes a validation error.&lt;br /&gt; &lt;img class=" alignnone size-full wp-image-654047 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/10_level_value-1024x369.gif" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/10_level_value.gif" alt="" width="1417" height="511" /&gt;&lt;/p&gt; &lt;h3&gt;Documentation for default profiles&lt;/h3&gt; &lt;p&gt;Currently, there are three default profiles for the &lt;code&gt;application.properties&lt;/code&gt; file: &lt;code&gt;%dev&lt;/code&gt;, &lt;code&gt;%prod&lt;/code&gt; and &lt;code&gt;%test&lt;/code&gt;. Hovering over a default property or invoking completion after a &lt;code&gt;%&lt;/code&gt; sign will now provide relevant documentation:&lt;br /&gt; &lt;img class=" alignnone size-full wp-image-654067 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/11_profile_doc-1024x369.gif" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/11_profile_doc.gif" alt="" width="1417" height="511" /&gt;&lt;/p&gt; &lt;h3&gt;Validating user input for a new project&lt;/h3&gt; &lt;p&gt;Last but not least, when generating a new project in using the wizard, the input validation messages are now more helpful. There are different naming restrictions for the groupId, artifactId, package name, etc. which the validation messages now describe:&lt;br /&gt; &lt;img class=" alignnone size-full wp-image-654077 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/12_project_validation-1024x243.gif" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/12_project_validation.gif" alt="" width="1044" height="248" /&gt;&lt;/p&gt; &lt;p&gt;This wraps up the new features for this release. We would be ecstatic to hear any feedback and suggestions, as we take them very seriously. Thank you for reading, and stay tuned for the next release!&lt;/p&gt; &lt;h3&gt;Resources&lt;/h3&gt; &lt;p&gt;VS Code Marketplace: &lt;a href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-quarkus"&gt;https://marketplace.visualstudio.com/items?itemName=redhat.vscode-quarkus&lt;/a&gt;&lt;/p&gt; &lt;p&gt;GitHub repository: &lt;a href="https://github.com/redhat-developer/vscode-quarkus"&gt;https://github.com/redhat-developer/vscode-quarkus&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Open a GitHub issue: &lt;a href="https://github.com/redhat-developer/vscode-quarkus/issues"&gt;https://github.com/redhat-developer/vscode-quarkus/issues&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Changelog: &lt;a href="https://github.com/redhat-developer/vscode-quarkus/blob/master/CHANGELOG.md"&gt;https://github.com/redhat-developer/vscode-quarkus/blob/master/CHANGELOG.md &lt;/a&gt;&lt;/p&gt; &lt;p&gt;Quarkus Tools for Visual Studio Code 1.0.0 release: &lt;a href="https://quarkus.io/blog/quarkus-developer-joy-for-vs-code/"&gt;https://quarkus.io/blog/quarkus-developer-joy-for-vs-code/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F21%2Fnew-features-in-quarkus-tools-for-visual-studio-code-1-2-0%2F&amp;#38;linkname=New%20features%20in%20Quarkus%20Tools%20for%20Visual%20Studio%20Code%201.2.0" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F21%2Fnew-features-in-quarkus-tools-for-visual-studio-code-1-2-0%2F&amp;#38;linkname=New%20features%20in%20Quarkus%20Tools%20for%20Visual%20Studio%20Code%201.2.0" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F21%2Fnew-features-in-quarkus-tools-for-visual-studio-code-1-2-0%2F&amp;#38;linkname=New%20features%20in%20Quarkus%20Tools%20for%20Visual%20Studio%20Code%201.2.0" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F21%2Fnew-features-in-quarkus-tools-for-visual-studio-code-1-2-0%2F&amp;#38;linkname=New%20features%20in%20Quarkus%20Tools%20for%20Visual%20Studio%20Code%201.2.0" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F21%2Fnew-features-in-quarkus-tools-for-visual-studio-code-1-2-0%2F&amp;#38;linkname=New%20features%20in%20Quarkus%20Tools%20for%20Visual%20Studio%20Code%201.2.0" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F21%2Fnew-features-in-quarkus-tools-for-visual-studio-code-1-2-0%2F&amp;#38;linkname=New%20features%20in%20Quarkus%20Tools%20for%20Visual%20Studio%20Code%201.2.0" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F21%2Fnew-features-in-quarkus-tools-for-visual-studio-code-1-2-0%2F&amp;#38;linkname=New%20features%20in%20Quarkus%20Tools%20for%20Visual%20Studio%20Code%201.2.0" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F21%2Fnew-features-in-quarkus-tools-for-visual-studio-code-1-2-0%2F&amp;#038;title=New%20features%20in%20Quarkus%20Tools%20for%20Visual%20Studio%20Code%201.2.0" data-a2a-url="https://developers.redhat.com/blog/2019/11/21/new-features-in-quarkus-tools-for-visual-studio-code-1-2-0/" data-a2a-title="New features in Quarkus Tools for Visual Studio Code 1.2.0"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/11/21/new-features-in-quarkus-tools-for-visual-studio-code-1-2-0/"&gt;New features in Quarkus Tools for Visual Studio Code 1.2.0&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/WA9IloC7oHg" height="1" width="1" alt=""/&gt;</content><summary>We are proud to present the new release of Quarkus Tools for Visual Studio Code, providing a feature-rich development experience in VS Code for Quarkus application development. This release focused on introducing tooling support for Gradle projects, as well as adding new application.properties language features. Watch a demo of the new features: New features Gradle — Generate new Quarkus project G...</summary><dc:creator>David Kwon</dc:creator><dc:date>2019-11-21T08:00:04Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/11/21/new-features-in-quarkus-tools-for-visual-studio-code-1-2-0/</feedburner:origLink></entry><entry><title>Kogito deep dive video from Devoxx</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/udVxq_vwDbs/kogito-deep-dive-video-from-devoxx.html" /><category term="feed_group_name_jbpm" scheme="searchisko:content:tags" /><category term="feed_name_kverlaen" scheme="searchisko:content:tags" /><category term="kogito" scheme="searchisko:content:tags" /><category term="Presentation" scheme="searchisko:content:tags" /><category term="video" scheme="searchisko:content:tags" /><author><name>Kris Verlaenen</name></author><id>searchisko:content:id:jbossorg_blog-kogito_deep_dive_video_from_devoxx</id><updated>2019-11-20T12:20:12Z</updated><published>2019-11-20T12:20:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div style="text-align: justify;"&gt;This year at &lt;a href="https://devoxx.be/"&gt;Devoxx Belgium&lt;/a&gt;, Maciej, Edoardo and Mario held a &lt;a href="https://devoxx.be/talk/?id=44155"&gt;3h deep dive on Kogito&lt;/a&gt;.&amp;nbsp; Since Devoxx is so awesome to share the recordings of all their presentation online, wanted to give everyone the opportunity to go and watch this!&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;iframe width="320" height="266" class="YOUTUBE-iframe-video" data-thumbnail-src="https://i.ytimg.com/vi/KBkX6v57Jbo/0.jpg" src="https://www.youtube.com/embed/KBkX6v57Jbo?feature=player_embedded" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;I also had the opportunity to help out at the Red Hat booth for 2 days, and it was a great opportunity to sync up with a lot of people and do some Kogito evangelization.&amp;nbsp; And was there live for the big &lt;a href="https://quarkus.io/blog/announcing-quarkus-1-0/"&gt;announcement of Quarkus doing its 1.0 release&lt;/a&gt; !&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-TJwURWh6elI/XdUt8tavtUI/AAAAAAAAFRU/XXWEVFjIQdEoZNoeZQ44TFzWqkaIEUh9wCLcBGAsYHQ/s1600/EIy9sS-XYAANrU8.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="510" data-original-width="680" height="300" src="https://1.bp.blogspot.com/-TJwURWh6elI/XdUt8tavtUI/AAAAAAAAFRU/XXWEVFjIQdEoZNoeZQ44TFzWqkaIEUh9wCLcBGAsYHQ/s400/EIy9sS-XYAANrU8.jpg" width="400" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/udVxq_vwDbs" height="1" width="1" alt=""/&gt;</content><summary>This year at Devoxx Belgium, Maciej, Edoardo and Mario held a 3h deep dive on Kogito.  Since Devoxx is so awesome to share the recordings of all their presentation online, wanted to give everyone the opportunity to go and watch this! I also had the opportunity to help out at the Red Hat booth for 2 days, and it was a great opportunity to sync up with a lot of people and do some Kogito evangelizati...</summary><dc:creator>Kris Verlaenen</dc:creator><dc:date>2019-11-20T12:20:00Z</dc:date><feedburner:origLink>http://kverlaen.blogspot.com/2019/11/kogito-deep-dive-video-from-devoxx.html</feedburner:origLink></entry><entry><title>Fixing the oc and Red Hat OpenShift install “not downloaded” error on macOS</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Riry6KruZUc/" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Mac" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><author><name>Don Schenck</name></author><id>searchisko:content:id:jbossorg_blog-fixing_the_oc_and_red_hat_openshift_install_not_downloaded_error_on_macos</id><updated>2019-11-20T08:00:12Z</updated><published>2019-11-20T08:00:12Z</published><content type="html">&lt;p&gt;I recently decided to use my macOS machine to create a Red Hat OpenShift cluster. After downloading the &lt;code&gt;openshift-install&lt;/code&gt; command-line tool and running it, however, I received the following error:&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-full wp-image-653817 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-14-at-9.00.37-AM.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-14-at-9.00.37-AM.png" alt="" width="416" height="191" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-14-at-9.00.37-AM.png 416w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-14-at-9.00.37-AM-300x138.png 300w" sizes="(max-width: 416px) 100vw, 416px" /&gt;&lt;/p&gt; &lt;p&gt;(Yes, I know the above error is related to the &lt;code&gt;oc&lt;/code&gt; command, but it also threw the error and, after I fixed the &lt;code&gt;openshift-install&lt;/code&gt; command, I was unable to &amp;#8220;unfix&amp;#8221; it.)&lt;span id="more-653807"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Inside talk&lt;/h2&gt; &lt;p&gt;This error is thrown by the macOS &amp;#8220;Gatekeeper&amp;#8221; subsystem, which checks to make sure executables are notarized by the builder. Any app that is downloaded from the App Store must first be notarized. Apps are that not installed via the App Store may still be notarized by the developer — that&amp;#8217;s a choice they make. However, un-notarized applications will throw this error, and you are stopped.&lt;/p&gt; &lt;h2&gt;The answer&lt;/h2&gt; &lt;p&gt;The answer is quite simple: Find the application in Finder, right-click on it, select Open, and it will display a dialog box like this:&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-full wp-image-653827 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-14-at-9.17.25-AM.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-14-at-9.17.25-AM.png" alt="" width="419" height="222" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-14-at-9.17.25-AM.png 419w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screen-Shot-2019-11-14-at-9.17.25-AM-300x159.png 300w" sizes="(max-width: 419px) 100vw, 419px" /&gt;&lt;/p&gt; &lt;p&gt;Simply click the &amp;#8220;Open&amp;#8221; button, and the app will be regarded as safe. You can now execute it from the command line with no problems.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F20%2Ffixing-the-oc-and-red-hat-openshift-install-not-downloaded-error-on-macos%2F&amp;#38;linkname=Fixing%20the%20oc%20and%20Red%20Hat%20OpenShift%20install%20%E2%80%9Cnot%20downloaded%E2%80%9D%20error%20on%20macOS" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F20%2Ffixing-the-oc-and-red-hat-openshift-install-not-downloaded-error-on-macos%2F&amp;#38;linkname=Fixing%20the%20oc%20and%20Red%20Hat%20OpenShift%20install%20%E2%80%9Cnot%20downloaded%E2%80%9D%20error%20on%20macOS" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F20%2Ffixing-the-oc-and-red-hat-openshift-install-not-downloaded-error-on-macos%2F&amp;#38;linkname=Fixing%20the%20oc%20and%20Red%20Hat%20OpenShift%20install%20%E2%80%9Cnot%20downloaded%E2%80%9D%20error%20on%20macOS" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F20%2Ffixing-the-oc-and-red-hat-openshift-install-not-downloaded-error-on-macos%2F&amp;#38;linkname=Fixing%20the%20oc%20and%20Red%20Hat%20OpenShift%20install%20%E2%80%9Cnot%20downloaded%E2%80%9D%20error%20on%20macOS" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F20%2Ffixing-the-oc-and-red-hat-openshift-install-not-downloaded-error-on-macos%2F&amp;#38;linkname=Fixing%20the%20oc%20and%20Red%20Hat%20OpenShift%20install%20%E2%80%9Cnot%20downloaded%E2%80%9D%20error%20on%20macOS" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F20%2Ffixing-the-oc-and-red-hat-openshift-install-not-downloaded-error-on-macos%2F&amp;#38;linkname=Fixing%20the%20oc%20and%20Red%20Hat%20OpenShift%20install%20%E2%80%9Cnot%20downloaded%E2%80%9D%20error%20on%20macOS" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F20%2Ffixing-the-oc-and-red-hat-openshift-install-not-downloaded-error-on-macos%2F&amp;#38;linkname=Fixing%20the%20oc%20and%20Red%20Hat%20OpenShift%20install%20%E2%80%9Cnot%20downloaded%E2%80%9D%20error%20on%20macOS" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F20%2Ffixing-the-oc-and-red-hat-openshift-install-not-downloaded-error-on-macos%2F&amp;#038;title=Fixing%20the%20oc%20and%20Red%20Hat%20OpenShift%20install%20%E2%80%9Cnot%20downloaded%E2%80%9D%20error%20on%20macOS" data-a2a-url="https://developers.redhat.com/blog/2019/11/20/fixing-the-oc-and-red-hat-openshift-install-not-downloaded-error-on-macos/" data-a2a-title="Fixing the oc and Red Hat OpenShift install “not downloaded” error on macOS"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/11/20/fixing-the-oc-and-red-hat-openshift-install-not-downloaded-error-on-macos/"&gt;Fixing the oc and Red Hat OpenShift install &amp;#8220;not downloaded&amp;#8221; error on macOS&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Riry6KruZUc" height="1" width="1" alt=""/&gt;</content><summary>I recently decided to use my macOS machine to create a Red Hat OpenShift cluster. After downloading the openshift-install command-line tool and running it, however, I received the following error: (Yes, I know the above error is related to the oc command, but it also threw the error and, after I fixed the openshift-install command, I was unable to “unfix” it.) Inside talk This error is thrown by t...</summary><dc:creator>Don Schenck</dc:creator><dc:date>2019-11-20T08:00:12Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/11/20/fixing-the-oc-and-red-hat-openshift-install-not-downloaded-error-on-macos/</feedburner:origLink></entry><entry><title>Red Hat Software Collections 3.4 and Red Hat Developer Toolset 9 Beta now available</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Qi6hIo2V93M/" /><category term="Developer Tools" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="Red Hat Software Collections 3.4" scheme="searchisko:content:tags" /><author><name>Brian Gollaher</name></author><id>searchisko:content:id:jbossorg_blog-red_hat_software_collections_3_4_and_red_hat_developer_toolset_9_beta_now_available</id><updated>2019-11-19T08:02:46Z</updated><published>2019-11-19T08:02:46Z</published><content type="html">&lt;p&gt;The latest versions of &lt;a href="https://developers.redhat.com/products/softwarecollections/overview"&gt;Red Hat Software Collections&lt;/a&gt; and &lt;a href="https://developers.redhat.com/products/developertoolset/overview"&gt;Red Hat Developer Toolset&lt;/a&gt; are available now in beta. Red Hat Software Collections 3.4 delivers the latest stable versions of many popular open source runtime languages and databases natively to the &lt;a href="https://www.redhat.com/en/technologies/linux-platforms/enterprise-linux"&gt; world’s leading enterprise Linux platform&lt;/a&gt;. These components are supported for up to five years, helping to enable a more consistent, efficient, and reliable developer experience.&lt;span id="more-654677"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;New collections in the latest release of &lt;a href="https://developers.redhat.com/products/softwarecollections/overview"&gt;Red Hat Software Collections&lt;/a&gt; include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;Node.js 12&lt;/b&gt; — Provides a 30% faster startup time, improved diagnostics, and easier-to-use native modules.&lt;/li&gt; &lt;li&gt;&lt;b&gt;PHP 7.3&lt;/b&gt; — The latest version of the popular web development language boosts performance speed by nearly 10% over PHP 7.2.&lt;/li&gt; &lt;li&gt;&lt;b&gt;NGINX 1.16&lt;/b&gt; — Adds dynamic certificate loading, two-stage rate limiting, and improvements to UDP proxying.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Maven 3.6&lt;/b&gt; — Is aimed at helping developers manage a software project’s build, reporting and documentation from a central repository.&lt;/li&gt; &lt;li&gt;&lt;b&gt;PostgreSQL 12&lt;/b&gt; — The latest stable version of the open source PostgreSQL database provides performance and usability enhancements to increase overall application speed and stability.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Available with Red Hat Software Collections 3.4 is &lt;a href="https://developers.redhat.com/products/developertoolset/overview"&gt;Red Hat Developer Toolset 9&lt;/a&gt;, a curated collection of compilers, toolchains, debuggers, and other critical development tools. Forming the foundation of Developer Toolset 9 is GCC 9.1, the latest stable release of the popular open source compiler collection. Additional updates in Developer Toolset 9 center on delivering stable version of C/C++ debugging and performance tools.&lt;/p&gt; &lt;p&gt;All new collections in Red Hat Software Collections 3.4 are also available as &lt;a href="https://connect.redhat.com/explore/red-hat-container-certification"&gt;Red Hat Certified Containers&lt;/a&gt; through the &lt;a href="https://access.redhat.com/containers/"&gt;Red Hat Container Catalog&lt;/a&gt;. This makes it easier to build and deploy mission-critical applications using the supported components of Red Hat Software Collections for Red Hat Enterprise Linux and &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Red Hat OpenShift&lt;/a&gt; environments.&lt;/p&gt; &lt;p&gt;Red Hat Software Collections 3.4 continues Red Hat’s commitment to customer choice in terms of the underlying compute architecture, with availability across x86_64, ppc64le, s390x, and aarch64 hardware.&lt;/p&gt; &lt;p&gt;Red Hat customers with active &lt;a href="https://developers.redhat.com/blog/2019/08/21/why-you-should-be-developing-on-red-hat-enterprise-linux/"&gt;Red Hat Enterprise Linux&lt;/a&gt; subscriptions can access Red Hat Software Collections via the &lt;a href="https://access.redhat.com/solutions/472793"&gt;Red Hat Software Collections repository&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;For more information, please read the full &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_software_collections/3-beta/"&gt;beta release notes.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F19%2Fred-hat-software-collections-3-4-and-red-hat-developer-toolset-9-beta-now-available%2F&amp;#38;linkname=Red%20Hat%20Software%20Collections%203.4%20and%20Red%20Hat%20Developer%20Toolset%209%20Beta%20now%20available" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F19%2Fred-hat-software-collections-3-4-and-red-hat-developer-toolset-9-beta-now-available%2F&amp;#38;linkname=Red%20Hat%20Software%20Collections%203.4%20and%20Red%20Hat%20Developer%20Toolset%209%20Beta%20now%20available" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F19%2Fred-hat-software-collections-3-4-and-red-hat-developer-toolset-9-beta-now-available%2F&amp;#38;linkname=Red%20Hat%20Software%20Collections%203.4%20and%20Red%20Hat%20Developer%20Toolset%209%20Beta%20now%20available" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F19%2Fred-hat-software-collections-3-4-and-red-hat-developer-toolset-9-beta-now-available%2F&amp;#38;linkname=Red%20Hat%20Software%20Collections%203.4%20and%20Red%20Hat%20Developer%20Toolset%209%20Beta%20now%20available" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F19%2Fred-hat-software-collections-3-4-and-red-hat-developer-toolset-9-beta-now-available%2F&amp;#38;linkname=Red%20Hat%20Software%20Collections%203.4%20and%20Red%20Hat%20Developer%20Toolset%209%20Beta%20now%20available" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F19%2Fred-hat-software-collections-3-4-and-red-hat-developer-toolset-9-beta-now-available%2F&amp;#38;linkname=Red%20Hat%20Software%20Collections%203.4%20and%20Red%20Hat%20Developer%20Toolset%209%20Beta%20now%20available" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F19%2Fred-hat-software-collections-3-4-and-red-hat-developer-toolset-9-beta-now-available%2F&amp;#38;linkname=Red%20Hat%20Software%20Collections%203.4%20and%20Red%20Hat%20Developer%20Toolset%209%20Beta%20now%20available" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F19%2Fred-hat-software-collections-3-4-and-red-hat-developer-toolset-9-beta-now-available%2F&amp;#038;title=Red%20Hat%20Software%20Collections%203.4%20and%20Red%20Hat%20Developer%20Toolset%209%20Beta%20now%20available" data-a2a-url="https://developers.redhat.com/blog/2019/11/19/red-hat-software-collections-3-4-and-red-hat-developer-toolset-9-beta-now-available/" data-a2a-title="Red Hat Software Collections 3.4 and Red Hat Developer Toolset 9 Beta now available"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/11/19/red-hat-software-collections-3-4-and-red-hat-developer-toolset-9-beta-now-available/"&gt;Red Hat Software Collections 3.4 and Red Hat Developer Toolset 9 Beta now available&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Qi6hIo2V93M" height="1" width="1" alt=""/&gt;</content><summary>The latest versions of Red Hat Software Collections and Red Hat Developer Toolset are available now in beta. Red Hat Software Collections 3.4 delivers the latest stable versions of many popular open source runtime languages and databases natively to the world’s leading enterprise Linux platform. These components are supported for up to five years, helping to enable a more consistent, efficient, an...</summary><dc:creator>Brian Gollaher</dc:creator><dc:date>2019-11-19T08:02:46Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/11/19/red-hat-software-collections-3-4-and-red-hat-developer-toolset-9-beta-now-available/</feedburner:origLink></entry><entry><title>Decoupling microservices with Apache Camel and Debezium</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/muelRT2KvJg/" /><category term="apache camel" scheme="searchisko:content:tags" /><category term="debezium" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="integration" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="Red Hat Fuse" scheme="searchisko:content:tags" /><author><name>squake</name></author><id>searchisko:content:id:jbossorg_blog-decoupling_microservices_with_apache_camel_and_debezium</id><updated>2019-11-19T08:00:53Z</updated><published>2019-11-19T08:00:53Z</published><content type="html">&lt;p&gt;The rise of &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt;-oriented architecture brought us new development paradigms and mantras about independent development and decoupling. In such a scenario, we have to deal with a situation where we aim for independence, but we still need to react to state changes in different enterprise domains.&lt;/p&gt; &lt;p&gt;I&amp;#8217;ll use a simple and typical example in order to show what we&amp;#8217;re talking about. Imagine the development of two independent microservices: &lt;code&gt;Order&lt;/code&gt; and &lt;code&gt;User&lt;/code&gt;. We designed them to expose a REST interface and to each use a separate database, as shown in Figure 1:&lt;/p&gt; &lt;div id="attachment_648347" style="width: 628px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-648347" class="wp-image-648347 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/diagram-1.png" alt="Diagram 1 - Order and User microservices" width="618" height="331" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/diagram-1.png 618w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/diagram-1-300x161.png 300w" sizes="(max-width: 618px) 100vw, 618px" /&gt;&lt;p id="caption-attachment-648347" class="wp-caption-text"&gt;Figure 1: Order and User microservices.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;span id="more-648217"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;We must notify the &lt;code&gt;User&lt;/code&gt; domain about any change happening in the &lt;code&gt;Order&lt;/code&gt; domain. To do this in the example, we need to update the &lt;code&gt;order_list&lt;/code&gt;. For this reason, we&amp;#8217;ve modeled the User REST service with &lt;code&gt;addOrder&lt;/code&gt; and &lt;code&gt;deleteOrder&lt;/code&gt; operations.&lt;/p&gt; &lt;h2&gt;Solution 1: Queue decoupling&lt;/h2&gt; &lt;p&gt;The first solution to consider is adding a queue between the services. &lt;code&gt;Order&lt;/code&gt; will publish events that &lt;code&gt;User&lt;/code&gt; will eventually process, as shown in Figure 2:&lt;/p&gt; &lt;div id="attachment_648337" style="width: 338px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-648337" class="wp-image-648337 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/diagram-2.png" alt="Diagram 2 - decoupling with a queue" width="328" height="431" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/diagram-2.png 328w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/diagram-2-228x300.png 228w" sizes="(max-width: 328px) 100vw, 328px" /&gt;&lt;p id="caption-attachment-648337" class="wp-caption-text"&gt;Figure 2: Decoupling with a queue.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;This is a fair design. However, if you don&amp;#8217;t use the right middleware you will mix a lot of &lt;em&gt;infrastructure code&lt;/em&gt; into your &lt;em&gt;domain logic. &lt;/em&gt;Now that you have queues, you must develop &lt;em&gt;producer&lt;/em&gt; and &lt;em&gt;consumer logic&lt;/em&gt;. You also have to take care of &lt;em&gt;transactions. &lt;/em&gt;The problem is to make sure that every event ends up correctly in both the &lt;code&gt;Order&lt;/code&gt; database and in the queue.&lt;/p&gt; &lt;h2&gt;Solution 2: Change data capture decoupling&lt;/h2&gt; &lt;p&gt;Let me introduce an alternative solution that handles all of that work without your touching any line of your microservices code. I&amp;#8217;ll use &lt;a href="https://debezium.io/" target="_blank" rel="noopener noreferrer"&gt;Debezium&lt;/a&gt; and &lt;a href="https://camel.apache.org/" target="_blank" rel="noopener noreferrer"&gt;Apache Camel&lt;/a&gt; to capture data changes on &lt;code&gt;Order&lt;/code&gt; and trigger certain actions on &lt;code&gt;User&lt;/code&gt;. Debezium is a log-based data change capture middleware. Camel is an integration framework that simplifies the integration between a source (&lt;code&gt;Order&lt;/code&gt;) and a destination (&lt;code&gt;User&lt;/code&gt;), as shown in Figure 3:&lt;/p&gt; &lt;div id="attachment_648327" style="width: 501px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-648327" class="wp-image-648327 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/diagram-3.png" alt="Diagram 3 - decoupling with Debezium and Camel" width="491" height="429" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/diagram-3.png 491w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/diagram-3-300x262.png 300w" sizes="(max-width: 491px) 100vw, 491px" /&gt;&lt;p id="caption-attachment-648327" class="wp-caption-text"&gt;Figure 3: Decoupling with Debezium and Camel.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Debezium is in charge of capturing any data change happening in the &lt;code&gt;Order&lt;/code&gt; domain and publishing it to a &lt;em&gt;topic&lt;/em&gt;. Then a Camel consumer can pick that event and make a REST call to the &lt;code&gt;User&lt;/code&gt; API to perform the necessary action expected by its domain (in our simple case, update the list).&lt;/p&gt; &lt;h2&gt;Decoupling with Debezium and Camel&lt;/h2&gt; &lt;p&gt;I&amp;#8217;ve prepared a simple demo with all of the components we need to run the example above. You can find this demo &lt;a href="https://github.com/squakez/debezium-camel-demo" target="_blank" rel="noopener noreferrer"&gt;in this GitHub repo&lt;/a&gt;. The only part we need to develop is represented by the following source code:&lt;/p&gt; &lt;pre&gt;public class MyRouteBuilder extends RouteBuilder { public void configure() { from("debezium:mysql?name=my-sql-connector" + "&amp;#38;databaseServerId=1" + "&amp;#38;databaseHostName=localhost" + "&amp;#38;databaseUser=debezium" + "&amp;#38;databasePassword=dbz" + "&amp;#38;databaseServerName=my-app-connector" + "&amp;#38;databaseHistoryFileName=/tmp/dbhistory.dat" + "&amp;#38;databaseWhitelist=debezium" + "&amp;#38;tableWhitelist=debezium._order" + "&amp;#38;offsetStorageFileName=/tmp/offset.dat") .choice() .when(header(DebeziumConstants.HEADER_OPERATION).isEqualTo("c")) .process(new AfterStructToOrderTranslator()) .to("rest-swagger:http://localhost:8082/v2/api-docs#addOrderUsingPOST") .when(header(DebeziumConstants.HEADER_OPERATION).isEqualTo("d")) .process(new BeforeStructToOrderTranslator()) .to("rest-swagger:http://localhost:8082/v2/api-docs#deleteOrderUsingDELETE") .log("Response : ${body}"); } } &lt;/pre&gt; &lt;p&gt;That&amp;#8217;s it. Really. We don&amp;#8217;t need anything else.&lt;/p&gt; &lt;p&gt;Apache Camel has a &lt;a href="https://camel.apache.org/components/latest/debezium-mysql-component.html"&gt;Debezium component&lt;/a&gt; that can hook up a MySQL database and use &lt;a href="https://debezium.io/documentation/reference/0.9/operations/embedded.html" target="_blank" rel="noopener noreferrer"&gt;Debezium embedded engine&lt;/a&gt;. The source endpoint configuration provides the parameters needed by Debezium to note any change happening in the &lt;code&gt;debezium._order&lt;/code&gt; table. Debezium streams the events according to a JSON-defined format, so you know what kind of &lt;a href="https://debezium.io/documentation/reference/0.10/connectors/mysql.html#events" target="_blank" rel="noopener noreferrer"&gt;information to expect&lt;/a&gt;. For each event, you will get the information as it was &lt;em&gt;before&lt;/em&gt; and &lt;em&gt;after&lt;/em&gt; the event occurs, plus a few useful pieces of meta-information.&lt;/p&gt; &lt;p&gt;Thanks to Camel&amp;#8217;s content-based router, we can either call the &lt;code&gt;addOrderUsingPOST&lt;/code&gt; or &lt;code&gt;deleteOrderUsingDELETE&lt;/code&gt; operation. You only have to develop a message translator that can convert the message coming from Debezium:&lt;/p&gt; &lt;pre&gt;public class AfterStructToOrderTranslator implements Processor { private static final String EXPECTED_BODY_FORMAT = "{\"userId\":%d,\"orderId\":%d}"; public void process(Exchange exchange) throws Exception { final Map value = exchange.getMessage().getBody(Map.class); // Convert and set body int userId = (int) value.get("user_id"); int orderId = (int) value.get("order_id"); exchange.getIn().setHeader("userId", userId); exchange.getIn().setHeader("orderId", orderId); exchange.getIn().setBody(String.format(EXPECTED_BODY_FORMAT, userId, orderId)); } } &lt;/pre&gt; &lt;p&gt;Notice that we did not touch any of the base code for &lt;code&gt;Order&lt;/code&gt; or &lt;code&gt;User&lt;/code&gt;. Now, turn off the Debezium process to simulate downtime. You will see that it can recover all events as soon as it turns back on!&lt;/p&gt; &lt;p&gt;You can run the example provided by&lt;a href="https://github.com/squakez/debezium-camel-demo" target="_blank" rel="noopener noreferrer"&gt; following the instructions on this GitHub repo&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Caveat&lt;/h2&gt; &lt;p&gt;The example illustrated here uses Debezium&amp;#8217;s embedded mode. For more consistent solutions, consider using the Kafka connect mode instead, or &lt;a href="https://debezium.io/documentation/reference/0.10/operations/embedded.html#_handling_failures" target="_blank" rel="noopener noreferrer"&gt;tuning the embedded engine&lt;/a&gt; accordingly.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F19%2Fdecoupling-microservices-with-apache-camel-and-debezium%2F&amp;#38;linkname=Decoupling%20microservices%20with%20Apache%20Camel%20and%20Debezium" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F19%2Fdecoupling-microservices-with-apache-camel-and-debezium%2F&amp;#38;linkname=Decoupling%20microservices%20with%20Apache%20Camel%20and%20Debezium" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F19%2Fdecoupling-microservices-with-apache-camel-and-debezium%2F&amp;#38;linkname=Decoupling%20microservices%20with%20Apache%20Camel%20and%20Debezium" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F19%2Fdecoupling-microservices-with-apache-camel-and-debezium%2F&amp;#38;linkname=Decoupling%20microservices%20with%20Apache%20Camel%20and%20Debezium" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F19%2Fdecoupling-microservices-with-apache-camel-and-debezium%2F&amp;#38;linkname=Decoupling%20microservices%20with%20Apache%20Camel%20and%20Debezium" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F19%2Fdecoupling-microservices-with-apache-camel-and-debezium%2F&amp;#38;linkname=Decoupling%20microservices%20with%20Apache%20Camel%20and%20Debezium" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F19%2Fdecoupling-microservices-with-apache-camel-and-debezium%2F&amp;#38;linkname=Decoupling%20microservices%20with%20Apache%20Camel%20and%20Debezium" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F19%2Fdecoupling-microservices-with-apache-camel-and-debezium%2F&amp;#038;title=Decoupling%20microservices%20with%20Apache%20Camel%20and%20Debezium" data-a2a-url="https://developers.redhat.com/blog/2019/11/19/decoupling-microservices-with-apache-camel-and-debezium/" data-a2a-title="Decoupling microservices with Apache Camel and Debezium"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/11/19/decoupling-microservices-with-apache-camel-and-debezium/"&gt;Decoupling microservices with Apache Camel and Debezium&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/muelRT2KvJg" height="1" width="1" alt=""/&gt;</content><summary>The rise of microservices-oriented architecture brought us new development paradigms and mantras about independent development and decoupling. In such a scenario, we have to deal with a situation where we aim for independence, but we still need to react to state changes in different enterprise domains. I’ll use a simple and typical example in order to show what we’re talking about. Imagine the dev...</summary><dc:creator>squake</dc:creator><dc:date>2019-11-19T08:00:53Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/11/19/decoupling-microservices-with-apache-camel-and-debezium/</feedburner:origLink></entry><entry><title>Byteman 4.0.9 has been released</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/QcKLo56sgcg/byteman-409-has-been-released.html" /><category term="feed_group_name_byteman" scheme="searchisko:content:tags" /><category term="feed_name_byteman" scheme="searchisko:content:tags" /><author><name>Andrew Dinn</name></author><id>searchisko:content:id:jbossorg_blog-byteman_4_0_9_has_been_released</id><updated>2019-11-18T17:12:00Z</updated><published>2019-11-18T17:12:00Z</published><content type="html">Byteman 4.0.9 is now available from the &lt;a href="http://www.jboss.org/byteman/downloads"&gt;Byteman downloads page&lt;/a&gt; and from the &lt;a href="https://oss.sonatype.org/index.html#nexus-search;quick%7Ebyteman"&gt;Maven Central repository&lt;/a&gt;. It is the latest update release for use on all JDK9+ runtimes. It is also recommended as the preferred release for use on JDK8- runtimes.&lt;br /&gt;&lt;br /&gt;Byteman 4.0.9 is a maintenance release which includes a small number of bug fixes. More details are provided in the &lt;a href="http://downloads.jboss.org/byteman/latest/ReleaseNotes.txt"&gt;Release Notes&lt;/a&gt;.&lt;br /&gt; &lt;div class="post-footer-line post-footer-line-1"&gt;&lt;span class="post-author vcard"&gt;&lt;br /&gt;&lt;/span&gt;&lt;span class="post-timestamp"&gt;&lt;a class="timestamp-link" href="https://bytemanblog.blogspot.com/2019/10/byteman-408-has-been-released.html" rel="bookmark" title="permanent link"&gt;&lt;abbr class="published" itemprop="datePublished" title="2019-10-14T16:16:00+01:00"&gt;&lt;/abbr&gt;&lt;/a&gt;&lt;/span&gt;&lt;span class="reaction-buttons"&gt;&lt;/span&gt;&lt;span class="post-comment-link"&gt;&lt;/span&gt;&lt;span class="post-backlinks post-comment-link"&gt;&lt;/span&gt;&lt;span class="post-icons"&gt; &lt;/span&gt;&lt;div class="post-share-buttons goog-inline-block"&gt;&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/QcKLo56sgcg" height="1" width="1" alt=""/&gt;</content><summary>Byteman 4.0.9 is now available from the Byteman downloads page and from the Maven Central repository. It is the latest update release for use on all JDK9+ runtimes. It is also recommended as the preferred release for use on JDK8- runtimes. Byteman 4.0.9 is a maintenance release which includes a small number of bug fixes. More details are provided in the Release Notes.</summary><dc:creator>Andrew Dinn</dc:creator><dc:date>2019-11-18T17:12:00Z</dc:date><feedburner:origLink>http://bytemanblog.blogspot.com/2019/11/byteman-409-has-been-released.html</feedburner:origLink></entry></feed>
